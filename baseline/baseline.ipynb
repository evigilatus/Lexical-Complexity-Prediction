{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lcp_multi_train.tsv', 'lcp_single_train.tsv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import spatial\n",
    "print(os.listdir('train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single_tsv = 'train/lcp_single_train.tsv'\n",
    "df_train_single = pd.read_csv(train_single_tsv, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data columns: \n",
      "\n",
      "Index(['id', 'corpus', 'sentence', 'token', 'complexity'], dtype='object')\n",
      "Total corpus len: 7662\n",
      "Subcorpus len:\n",
      "\n",
      "biomed      2576\n",
      "bible       2574\n",
      "europarl    2512\n",
      "Name: corpus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Data columns: \\n\")\n",
    "print(df_train_single.columns)\n",
    "print(\"Total corpus len: {}\".format(len(df_train_single)))\n",
    "print(\"Subcorpus len:\\n\")\n",
    "print(df_train_single['corpus'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_tsv = 'test/lcp_single_test.tsv'\n",
    "df_test_single = pd.read_csv(test_single_tsv, sep='\\t', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data columns: \n",
      "\n",
      "Index(['id', 'corpus', 'sentence', 'token', 'complexity'], dtype='object')\n",
      "Total corpus len: 917\n",
      "Subcorpus len:\n",
      "\n",
      "europarl    345\n",
      "biomed      289\n",
      "bible       283\n",
      "Name: corpus, dtype: int64\n",
      "C:\\Users\\Simona Mihaylova\n"
     ]
    }
   ],
   "source": [
    "print(\"Data columns: \\n\")\n",
    "print(df_test_single.columns)\n",
    "print(\"Total corpus len: {}\".format(len(df_test_single)))\n",
    "print(\"Subcorpus len:\\n\")\n",
    "print(df_test_single['corpus'].value_counts())\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_single_tsv = 'test/lcp_single_trial.tsv'\n",
    "df_trial_single = pd.read_csv(trial_single_tsv, sep='\\t', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data columns: \n",
      "\n",
      "Index(['id', 'subcorpus', 'sentence', 'token', 'complexity'], dtype='object')\n",
      "Total corpus len: 421\n",
      "Subcorpus len:\n",
      "\n",
      "europarl    143\n",
      "bible       143\n",
      "biomed      135\n",
      "Name: subcorpus, dtype: int64\n",
      "C:\\Users\\Simona Mihaylova\n"
     ]
    }
   ],
   "source": [
    "print(\"Data columns: \\n\")\n",
    "print(df_trial_single.columns)\n",
    "print(\"Total corpus len: {}\".format(len(df_trial_single)))\n",
    "print(\"Subcorpus len:\\n\")\n",
    "print(df_trial_single['subcorpus'].value_counts())\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe ###\n",
    "Load the pretrained GloVe vectors and verify that the operation has been successful by some quick experiments with the embedding.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "glove_w2v_loc = 'InferSent/GloVe/glove.6B.300d.txt'\n",
    "with open(glove_w2v_loc,  \"r\", encoding=\"utf8\") as lines:\n",
    "    glove_w2v = {}\n",
    "    for line in lines:\n",
    "        values = line.split()\n",
    "        word = ''.join(values[:-300])\n",
    "        vector = np.asarray(values[-300:], dtype='float32')\n",
    "        glove_w2v[word.lower()] = vector\n",
    "    print(len(glove_w2v),\" words loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_embeddings(embedding):\n",
    "    return sorted(glove_w2v.keys(), key=lambda word: spatial.distance.euclidean(glove_w2v[word.lower()], embedding))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo of closest words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['baby', 'babies', 'newborn', 'infant', 'birth']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Demo of closest words:\")\n",
    "find_closest_embeddings(glove_w2v['baby'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo of word arithmetics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['king', 'queen', 'monarch', 'mother', 'princess']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Demo of word arithmetics:\")\n",
    "find_closest_embeddings(np.array(glove_w2v['king']) - np.array(glove_w2v['man']) + np.array(glove_w2v['woman']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InferSent\n",
    "- https://towardsdatascience.com/learning-sentence-embeddings-by-natural-language-inference-a50b4661a0b8\n",
    "- https://research.fb.com/downloads/infersent/\n",
    "\n",
    "Load InferSent model and execute some experiments.  \n",
    "Currently it is using GloVe. We have tested GloVe and fastText and have chosen GloVe over fastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InferSent.models import InferSent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pkl = 'InferSent/encoder/infersent1.pkl'\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': 1}\n",
    "infer_sent_model = InferSent(params_model)\n",
    "infer_sent_model.load_state_dict(torch.load(model_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    }
   ],
   "source": [
    "infer_sent_model.set_w2v_path(glove_w2v_loc)\n",
    "infer_sent_model.build_vocab_k_words(K=100000)\n",
    "\n",
    "# infer_sent_model.to(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17863287,  0.08774212,  0.05200037, ...,  0.00108395,\n",
       "        -0.05402661,  0.03372178]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_sent_model.encode([\"This man is playing computer games\"], tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for single prediction: 0.0921173095703125\n",
      "Time for pred of 3000 cases: 18.23288059234619\n"
     ]
    }
   ],
   "source": [
    "def get_embedding_for_context(ctx):\n",
    "    if not isinstance(ctx, list):\n",
    "#       print(\"ctx is not list\")\n",
    "        ctx = [ctx]\n",
    "    return infer_sent_model.encode(ctx, tokenize=True)\n",
    "\n",
    "start = time.time()\n",
    "get_embedding_for_context(\"This is a test sentence\")\n",
    "print(\"Time for single prediction: {}\".format(time.time() - start))\n",
    "\n",
    "get_embedding_for_context([\"This is a test sentence\"] * 3000)\n",
    "print(\"Time for pred of 3000 cases: {}\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7978083]]\n",
      "[[0.8062569]]\n",
      "[[0.632438]]\n",
      "[[0.69138]]\n",
      "[[0.8188078]]\n",
      "[[0.77679014]]\n",
      "[[0.84341216]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def measure_dist_between_ctx(c1, c2):\n",
    "    e1 = get_embedding_for_context(c1)[0]\n",
    "    e2 = get_embedding_for_context(c2)[0]\n",
    "    #return spatial.distance.euclidean(e1, e2)\n",
    "    return cosine_similarity([e1], [e2])\n",
    "\n",
    "print(measure_dist_between_ctx(\"In India people are going to war.\", \"The family went to an indian restaurant.\"))\n",
    "print(measure_dist_between_ctx(\"The baby is hungry.\", \"The child needs to eat.\"))\n",
    "print(measure_dist_between_ctx(\"Programming takes ages to master.\", \"Ronaldo scored a goal against man united.\"))\n",
    "print(measure_dist_between_ctx(\"At the university students go to lectures.\", \"Ronaldo scored a goal against man united.\"))\n",
    "print(measure_dist_between_ctx(\"A soccer game with multiple males playing.\", \"Some men are playing a sport.\"))\n",
    "print(measure_dist_between_ctx(\"The man is cooking chicken with potatoes.\", \"A man is driving down a lonely road.\"))\n",
    "print(measure_dist_between_ctx(\"The man is cooking chicken with potatoes.\", \"In the restaurant they serve delicious food.\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handcrafted features\n",
    "\n",
    "* Word length\n",
    "* Syllable count\n",
    "* Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 3, 3.0782334950657346]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import syllables\n",
    "# According to the paper there are 3 handcrafted features\n",
    "# - word length\n",
    "# - word frequency \n",
    "# - syllable count\n",
    "import csv\n",
    "import math\n",
    "import nltk\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "reader = csv.reader(open('SUBTLEX.csv', 'r'))\n",
    "frequency = defaultdict(float)\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for row in reader:\n",
    "    frequency[stemmer.stem(row[0].lower())] += float(row[5])\n",
    "\n",
    "frequency = {k: math.log(v) for k, v in frequency.items()}\n",
    "\n",
    "def get_handcrafted_features(word):\n",
    "    word = str(word)\n",
    "    return [len(word), syllables.estimate(word), frequency.get(stemmer.stem(word.lower())) or 0]\n",
    "\n",
    "\n",
    "get_handcrafted_features(\"Basketball\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "def preprocess_embeddings(dataset):\n",
    "    # Preprocess all sentence embeddings for the data:\n",
    "    sentence_embeddings = {}\n",
    "    \n",
    "    all_sentences = dataset['sentence'].tolist()\n",
    "\n",
    "    start = time.time()\n",
    "    all_sentence_embeddings = get_embedding_for_context(all_sentences)\n",
    "    print(\"Encoding time for all sentences: {}\".format(time.time() - start))\n",
    "    return all_sentence_embeddings\n",
    "    \n",
    "\n",
    "class CompLexDataset(Dataset):\n",
    "    global dataset_type\n",
    "    \n",
    "    def __init__(self, dataset_type):\n",
    "        self.dataset_type = dataset_type\n",
    "        \n",
    "        if(self.dataset_type == 'train'):                   \n",
    "            self.all_sentence_embeddings = preprocess_embeddings(df_train_single)\n",
    "        elif(self.dataset_type == 'trial'):\n",
    "            self.all_sentence_embeddings = preprocess_embeddings(df_trial_single)\n",
    "        elif(self.dataset_type == 'test'):\n",
    "            self.all_sentence_embeddings = preprocess_embeddings(df_test_single)\n",
    "    \n",
    "    def __len__(self):\n",
    "        if(self.dataset_type == 'train'):                   \n",
    "            return len(df_train_single)\n",
    "        elif(self.dataset_type == 'trial'):\n",
    "            return len(df_trial_single)\n",
    "        elif(self.dataset_type == 'test'):\n",
    "            return len(df_test_single)\n",
    "        else: \n",
    "            raise Exception(\"Invalid dataset type.\", self.dataset_type)\n",
    "\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        start = time.time()\n",
    "        if(self.dataset_type == 'train'):\n",
    "            token = df_train_single.loc[idx, 'token']\n",
    "            token = str(token)\n",
    "            out = df_train_single.loc[idx, 'complexity']\n",
    "        elif(self.dataset_type == 'trial'):\n",
    "            token = df_trial_single.loc[idx, 'token']\n",
    "            token = str(token)\n",
    "            out = df_trial_single.loc[idx, 'complexity']\n",
    "        elif(self.dataset_type == 'test'):\n",
    "            token = df_test_single.loc[idx, 'token']\n",
    "            token = str(token)\n",
    "            out = df_test_single.loc[idx, 'complexity']\n",
    "        else: \n",
    "            raise Exception(\"Invalid dataset type.\", self.dataset_type)\n",
    "        \n",
    "        handcrafted_features = get_handcrafted_features(token)\n",
    "\n",
    "        sentence_ctx = self.all_sentence_embeddings[idx]\n",
    "        \n",
    "        if token.lower() in glove_w2v:   \n",
    "            w2v_for_token = glove_w2v[token.lower()]\n",
    "        else:\n",
    "            #print(\"Token {} not found\".format(token.lower()))\n",
    "            w2v_for_token = [0] * 300\n",
    "        \n",
    "        \n",
    "        result = {\n",
    "            'inp': torch.from_numpy(np.hstack((np.array(handcrafted_features), sentence_ctx, np.array(w2v_for_token))).ravel()).float(), \n",
    "            'out': torch.from_numpy(np.array([out])).float()\n",
    "        }\n",
    "        \n",
    "        #print(\"Idx {} fetch time: {}\".format(idx, time.time() - start))\n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simona Mihaylova\\InferSent\\models.py:207: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sentences = np.array(sentences)[idx_sort]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding time for all sentences: 274.9542806148529\n",
      "Input:  tensor([12.0000,  4.0000, -0.2614,  ...,  0.2898,  0.1594, -0.2284]) Input Length:  4399\n",
      "Output:  tensor([0.3750])\n",
      "Encoding time for all sentences: 16.22931694984436\n",
      "Input:  tensor([ 4.0000,  1.0000,  4.8308,  ..., -0.1070,  0.1319, -0.1578]) Input Length:  4399\n",
      "Output:  tensor([0.0250])\n",
      "Encoding time for all sentences: 34.14873957633972\n",
      "Input:  tensor([ 4.0000,  1.0000,  4.2922,  ..., -0.5007,  0.2014, -0.3354]) Input Length:  4399\n",
      "Output:  tensor([0.2500])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CompLexDataset(\"train\")\n",
    "print(\"Input: \", train_dataset[5]['inp'], \"Input Length: \", len(train_dataset[5]['inp']))\n",
    "print(\"Output: \", train_dataset[5]['out'])\n",
    "\n",
    "trial_dataset = CompLexDataset(\"trial\")\n",
    "print(\"Input: \", trial_dataset[5]['inp'], \"Input Length: \", len(trial_dataset[5]['inp']))\n",
    "print(\"Output: \", trial_dataset[5]['out'])\n",
    "\n",
    "test_dataset = CompLexDataset(\"test\")\n",
    "print(\"Input: \", test_dataset[5]['inp'], \"Input Length: \", len(test_dataset[5]['inp']))\n",
    "print(\"Output: \", test_dataset[5]['out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (fc1): Linear(in_features=4399, out_features=1600, bias=True)\n",
      "  (b1): BatchNorm1d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  (softmax): Softmax(dim=0)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inp': tensor([ 5.0000,  2.0000,  2.6844,  ...,  0.0829, -0.5269,  0.1076]),\n",
       " 'out': tensor([0.2143])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(len(train_dataset[0]['inp']), 1600)\n",
    "        self.b1 = nn.BatchNorm1d(1600)\n",
    "        self.fc2 = nn.Linear(1600, 1)\n",
    "        self.softmax = nn.Softmax(dim = 0) \n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        #x = self.b1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "        #return self.softmax(x)\n",
    "        \n",
    "    \n",
    "net = Network()\n",
    "print(net)\n",
    "#net.to(torch.device(\"cuda:0\"))\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y, optimizer, criterion):\n",
    "    model.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = criterion(output,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error ###\n",
    "Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss : 1.1088427305221558\n",
      "Epoch 2 Loss : 0.9720829129219055\n",
      "Epoch 3 Loss : 0.939026951789856\n",
      "Epoch 4 Loss : 0.9022021889686584\n",
      "Epoch 5 Loss : 0.9036809802055359\n",
      "Epoch 6 Loss : 0.859229564666748\n",
      "Epoch 7 Loss : 0.8599917888641357\n",
      "Epoch 8 Loss : 0.8424505591392517\n",
      "Epoch 9 Loss : 0.8321893215179443\n",
      "Epoch 10 Loss : 0.8420288562774658\n",
      "Epoch 11 Loss : 0.828995406627655\n",
      "Epoch 12 Loss : 0.817345380783081\n",
      "Epoch 13 Loss : 0.811475396156311\n",
      "Epoch 14 Loss : 0.8073127865791321\n",
      "Epoch 15 Loss : 0.7900136709213257\n",
      "Epoch 16 Loss : 0.8010743856430054\n",
      "Epoch 17 Loss : 0.7903727293014526\n",
      "Epoch 18 Loss : 0.7630934715270996\n",
      "Epoch 19 Loss : 0.7665468454360962\n",
      "Epoch 20 Loss : 0.7612242698669434\n",
      "Epoch 21 Loss : 0.7631808519363403\n",
      "Epoch 22 Loss : 0.7604466080665588\n",
      "Epoch 23 Loss : 0.7576807141304016\n",
      "Epoch 24 Loss : 0.7574282884597778\n",
      "Epoch 25 Loss : 0.7654207348823547\n",
      "Epoch 26 Loss : 0.7408734560012817\n",
      "Epoch 27 Loss : 0.725262463092804\n",
      "Epoch 28 Loss : 0.7236118912696838\n",
      "Epoch 29 Loss : 0.7249473929405212\n",
      "Epoch 30 Loss : 0.7187416553497314\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "optm = Adam(net.parameters(), lr = 0.00001)\n",
    "\n",
    "data_train = DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for bidx, batch in enumerate(data_train):\n",
    "        #start = time.time()\n",
    "        x_train = batch['inp']\n",
    "        y_train = batch['out']\n",
    "        #print(\"Fetch time: {}\".format(time.time() - start))\n",
    "        \n",
    "        #start = time.time()\n",
    "        loss, predictions = train(net,x_train,y_train, optm, criterion)\n",
    "        epoch_loss += loss\n",
    "        #print(\"Predict time: {}\".format(time.time() - start))\n",
    "        \n",
    "    print('Epoch {} Loss : {}'.format((epoch+1),epoch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output for single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2395], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(train_dataset[210]['inp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for test data:  0.07294992398726576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_true = [test_dataset[i]['out'].item() for i in range(len(test_dataset))]\n",
    "y_pred = []\n",
    "\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "for bidx, batch in enumerate(test_loader):\n",
    "        #start = time.time()\n",
    "        x_train = batch['inp']\n",
    "        y_pred.append(net(x_train))\n",
    "\n",
    "y_pred = [x.item() for i in range(len(y_pred)) for x in y_pred[i] ]\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(\"MAE for test data: \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE for trial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for trial data:  0.07172998721377301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_true = [trial_dataset[i]['out'].item() for i in range(len(trial_dataset))]\n",
    "y_pred = []\n",
    "\n",
    "trial_loader = DataLoader(dataset = trial_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "for bidx, batch in enumerate(trial_loader):\n",
    "        #start = time.time()\n",
    "        x_train = batch['inp']\n",
    "        y_pred.append(net(x_train))\n",
    "\n",
    "y_pred = [x.item() for i in range(len(y_pred)) for x in y_pred[i] ]\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(\"MAE for trial data: \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for train data:  0.05870204062072968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_true = [train_dataset[i]['out'].item() for i in range(len(train_dataset))]\n",
    "y_pred = []\n",
    "\n",
    "test_loader = DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "for bidx, batch in enumerate(test_loader):\n",
    "        #start = time.time()\n",
    "        x_train = batch['inp']\n",
    "        y_pred.append(net(x_train))\n",
    "\n",
    "y_pred = [x.item() for i in range(len(y_pred)) for x in y_pred[i] ]\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(\"MAE for train data: \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE for total random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for train data:  0.3059637870602539\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import random\n",
    "\n",
    "y_true = [train_dataset[i]['out'].item() for i in range(len(train_dataset))]\n",
    "y_pred = [random.random() for i in range(len(train_dataset))]\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(\"Mean Absolute Error for train data: \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentence(sentence, token):\n",
    "    sentence_embeddings = get_embedding_for_context(sentence)[0]\n",
    "    handcrafted_features = get_handcrafted_features(token)\n",
    "            \n",
    "    if token.lower() in glove_w2v:   \n",
    "        w2v_for_token = glove_w2v[token.lower()]\n",
    "    else:\n",
    "       w2v_for_token = [0] * 300\n",
    "    \n",
    "    return {\n",
    "            'inp': torch.from_numpy(np.hstack((np.array(handcrafted_features), sentence_embeddings, np.array(w2v_for_token))).ravel()).float() \n",
    "           }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE:  Peter loves pineapples and apples! \n",
      "TOKEN:  pineapples \n",
      "COMPLEXITY:  0.33662906289100647 \n",
      "\n",
      "SENTENCE:  Peter loves pineapples and apples! \n",
      "TOKEN:  apples \n",
      "COMPLEXITY:  0.1939375251531601 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Peter loves pineapples and apples!'\n",
    "token1 = 'pineapples'\n",
    "token2 = 'apples'\n",
    "token3 = 'Peter'\n",
    "\n",
    "y_pred1 = net(prepare_sentence(sentence, token1)['inp'])\n",
    "print('SENTENCE: ', sentence, '\\nTOKEN: ', token1, '\\nCOMPLEXITY: ', y_pred1.item(), '\\n')\n",
    "\n",
    "y_pred2 = net(prepare_sentence(sentence, token2)['inp'])\n",
    "print('SENTENCE: ', sentence, '\\nTOKEN: ', token2, '\\nCOMPLEXITY: ', y_pred2.item(), '\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
