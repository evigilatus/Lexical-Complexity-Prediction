{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-957a8531148b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspatial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import spatial\n",
    "print(os.listdir('train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_single_tsv = 'train/lcp_single_train.tsv'\n",
    "df_train_single = pd.read_csv(train_single_tsv, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data columns: \n",
      "\n",
      "Index(['id', 'corpus', 'sentence', 'token', 'complexity'], dtype='object')\n",
      "Total corpus len: 7232\n",
      "Subcorpus len:\n",
      "\n",
      "biomed      2576\n",
      "europarl    2512\n",
      "bible       2144\n",
      "Name: corpus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Data columns: \\n\")\n",
    "print(df_train_single.columns)\n",
    "print(\"Total corpus len: {}\".format(len(df_train_single)))\n",
    "print(\"Subcorpus len:\\n\")\n",
    "print(df_train_single['corpus'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_w2v_loc = 'glove.6B.300d.txt'\n",
    "with open(glove_w2v_loc,  \"r\", encoding=\"utf8\") as lines:\n",
    "    glove_w2v = {}\n",
    "    for line in lines:\n",
    "        split = line.split()\n",
    "        word = split[0]\n",
    "        vector = [float(i) for i in split[1:]]\n",
    "        glove_w2v[word.lower()] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_embeddings(embedding):\n",
    "    return sorted(glove_w2v.keys(), key=lambda word: spatial.distance.euclidean(glove_w2v[word.lower()], embedding))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo of closest words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['baby', 'babies', 'newborn', 'infant', 'birth']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Demo of closest words:\")\n",
    "find_closest_embeddings(glove_w2v['baby'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo of word arithmetics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['king', 'queen', 'monarch', 'mother', 'princess']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Demo of word arithmetics:\")\n",
    "find_closest_embeddings(np.array(glove_w2v['king']) - np.array(glove_w2v['man']) + np.array(glove_w2v['woman']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['king', 'queen', 'monarch', 'prince', 'kingdom']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_embeddings(np.array(glove_w2v['king']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['monk', 'nun', 'woman', 'nuns', 'monks']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_embeddings(np.array(glove_w2v['monk']) - np.array(glove_w2v['man']) + np.array(glove_w2v['woman']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo of word arithmetics:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'find_closest_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-35326a9da866>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Demo of word arithmetics:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfind_closest_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_w2v\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_w2v\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'europe'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'find_closest_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Demo of word arithmetics:\")\n",
    "find_closest_embeddings(np.array(glove_w2v['country']) + np.array(glove_w2v['europe']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage of InferSent\n",
    "https://towardsdatascience.com/learning-sentence-embeddings-by-natural-language-inference-a50b4661a0b8\n",
    "\n",
    "\n",
    "https://research.fb.com/downloads/infersent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InferSent.models import InferSent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkl = 'infersent1.pkl'\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': 1}\n",
    "infer_sent_model = InferSent(params_model)\n",
    "infer_sent_model.load_state_dict(torch.load(model_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InferSent(\n",
       "  (enc_lstm): LSTM(300, 2048, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_sent_model.set_w2v_path(glove_w2v_loc)\n",
    "infer_sent_model.build_vocab_k_words(K=100000)\n",
    "\n",
    "infer_sent_model.to(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1786329 ,  0.08774213,  0.05200032, ...,  0.00108394,\n",
       "        -0.05402661,  0.03372178]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_sent_model.encode([\"This man is playing computer games\"], tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctx is not list\n",
      "Single prediction: 0.01695394515991211\n",
      "pred of 3000 cases: 1.5830514430999756\n"
     ]
    }
   ],
   "source": [
    "def get_embedding_for_context(ctx):\n",
    "    if not isinstance(ctx, list):\n",
    "        print(\"ctx is not list\")\n",
    "        ctx = [ctx]\n",
    "    return infer_sent_model.encode(ctx, tokenize=True)\n",
    "\n",
    "start = time.time()\n",
    "get_embedding_for_context(\"This is a test sentence\")\n",
    "print(\"Single prediction: {}\".format(time.time() - start))\n",
    "\n",
    "get_embedding_for_context([\"This is a test sentence\"] * 3000)\n",
    "print(\"pred of 3000 cases: {}\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding time for all sentences: 21.364880561828613\n"
     ]
    }
   ],
   "source": [
    "# Preprocess all sentence embeddings for the data:\n",
    "sentence_embeddings = {}\n",
    "idx = 600\n",
    "all_sentences = df_train_single['sentence'].tolist()\n",
    "all_sentences[idx] == df_train_single.loc[idx, 'sentence']\n",
    "\n",
    "start = time.time()\n",
    "all_sentence_embeddings = get_embedding_for_context(all_sentences)\n",
    "print(\"Encoding time for all sentences: {}\".format(time.time() - start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7232\n",
      "7232\n"
     ]
    }
   ],
   "source": [
    "print(len(all_sentences))\n",
    "print(len(all_sentence_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctx is not list\n",
      "ctx is not list\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. check_pairwise_arrays expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d7e99ef1eeb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0me2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeasure_dist_between_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"In India people are going to war.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"The family went to an indian restaurant.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeasure_dist_between_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The baby is hungry.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"The child needs to eat.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeasure_dist_between_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Programming takes ages to master.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Ronaldo scored a goal against man united.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-d7e99ef1eeb6>\u001b[0m in \u001b[0;36mmeasure_dist_between_ctx\u001b[1;34m(c1, c2)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0me2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_embedding_for_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#return spatial.distance.euclidean(e1, e2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0me2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeasure_dist_between_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"In India people are going to war.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"The family went to an indian restaurant.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     \u001b[1;31m# to avoid recursive import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    139\u001b[0m         X = check_array(X, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[0;32m    140\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                         estimator=estimator)\n\u001b[0m\u001b[0;32m    142\u001b[0m         Y = check_array(Y, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[0;32m    143\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[1;32m--> 574\u001b[1;33m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. check_pairwise_arrays expected <= 2."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def measure_dist_between_ctx(c1, c2):\n",
    "    e1 = get_embedding_for_context(c1)\n",
    "    e2 = get_embedding_for_context(c2)\n",
    "    #return spatial.distance.euclidean(e1, e2)\n",
    "    return cosine_similarity([e1], [e2])\n",
    "\n",
    "print(measure_dist_between_ctx(\"In India people are going to war.\", \"The family went to an indian restaurant.\"))\n",
    "print(measure_dist_between_ctx(\"The baby is hungry.\", \"The child needs to eat.\"))\n",
    "print(measure_dist_between_ctx(\"Programming takes ages to master.\", \"Ronaldo scored a goal against man united.\"))\n",
    "print(measure_dist_between_ctx(\"At the university students go to lectures.\", \"Ronaldo scored a goal against man united.\"))\n",
    "print(measure_dist_between_ctx(\"A soccer game with multiple males playing.\", \"Some men are playing a sport.\"))\n",
    "print(measure_dist_between_ctx(\"The man is cooking chicken with potatoes.\", \"A man is driving down a lonely road.\"))\n",
    "print(measure_dist_between_ctx(\"The man is cooking chicken with potatoes.\", \"In the restaurant they serve delicious food.\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syllables\n",
    "# According to the paper there are 3 handcrafted features\n",
    "# - word lenghth\n",
    "# - word frequency\n",
    "# - syllable count\n",
    "def get_handcrafted_features(word):\n",
    "    word = str(word)\n",
    "    return [len(word), syllables.estimate(word)]\n",
    "\n",
    "get_handcrafted_features(\"Basketball\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CompLexDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(df_train_single)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start = time.time()\n",
    "        \n",
    "        token = df_train_single.loc[idx, 'token']\n",
    "        token = str(token)\n",
    "        out = df_train_single.loc[idx, 'complexity']\n",
    "        \n",
    "        handcrafted_features = get_handcrafted_features(token)\n",
    "        sentence_ctx = all_sentence_embeddings[idx]\n",
    "        \n",
    "        if token.lower() in glove_w2v:   \n",
    "            w2v_for_token = glove_w2v[token.lower()]\n",
    "        else:\n",
    "            #print(\"Token {} not found\".format(token.lower()))\n",
    "            w2v_for_token = [0] * 300\n",
    "        \n",
    "        \n",
    "        result = {\n",
    "            'inp': torch.from_numpy(np.hstack((np.array(handcrafted_features), sentence_ctx, np.array(w2v_for_token))).ravel()).float().to(torch.device(\"cuda:0\")),\n",
    "            'out': torch.from_numpy(np.array([out])).float().to(torch.device(\"cuda:0\"))\n",
    "        }\n",
    "        \n",
    "        #print(\"Idx {} fetch time: {}\".format(idx, time.time() - start))\n",
    "        return result\n",
    "    \n",
    "\n",
    "dataset = CompLexDataset()\n",
    "\n",
    "print(len(dataset[22]['out']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(len(dataset[0]['inp']), 1600)\n",
    "        self.b1 = nn.BatchNorm1d(1600)\n",
    "        self.fc2 = nn.Linear(1600, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        #x = self.b1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "net = Network()\n",
    "net.to(torch.device(\"cuda:0\"))\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y, optimizer, criterion):\n",
    "    model.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = criterion(output,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "optm = Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "data_train = DataLoader(dataset = dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for bidx, batch in enumerate(data_train):\n",
    "        #start = time.time()\n",
    "        x_train = batch['inp']\n",
    "        y_train = batch['out']\n",
    "        #print(\"Fetch time: {}\".format(time.time() - start))\n",
    "        \n",
    "        #start = time.time()\n",
    "        loss, predictions = train(net,x_train,y_train, optm, criterion)\n",
    "        epoch_loss+=loss\n",
    "        #print(\"Predict time: {}\".format(time.time() - start))\n",
    "        \n",
    "    print('Epoch {} Loss : {}'.format((epoch+1),epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
